{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to My Blog \u00b6 Go to my first article Go to my second article","title":"Home"},{"location":"#welcome-to-my-blog","text":"Go to my first article Go to my second article","title":"Welcome to My Blog"},{"location":"about/","text":"","title":"About"},{"location":"posts/post1/","text":"Basic performance tricks for porting kernels to the GPU. \u00b6 Some context and motivations \u00b6 Hello world! This is my first blog post. I'm R\u00e9mi Bourgeois, PhD. I am a researcher engineer working at the French Atomic Energy Comission (CEA). I work on the TRUST platform , a HPC (multi-GPU) CFD code that serves as a basis for many research/industrial applications. I was hired by CEA to join the porting effort of this legacy code to the GPU using Kokkos . This is quite a challenging task as the code is 20 years old, and more than 1400 kernels were identified to be ported to the GPU ! As I went and optimized some kernels, something struck me: The nature of the task of porting code to the GPU, especially when time is limited, often lead to small mistakes that can undermine performance. The goal of this blogpost is to give you basic , easy tips to keep in mind when writing / porting / first optimizing your kernels, so that you get a reasonable performance. By applying them, I was able to get: - A 40-50% speedup on a CFD convection kernel from TRUST (obtained on RTX A5000, RTX A6000 Ada and H100 GPUs). Brace yourself : this is a monstruous kernel. - A 40-50% speedup on a CFD diffusion kernel from TRUST (obtained on RTX A6000 Ada and H100 GPUs). - A 20% speedup on a MUSCL reconstruction kernel from the radiative hydrodynamics code heraclescpp - TODO: add ncu reports - A By reasonable I do not mean that you are getting optimal perfomance. In fact, I will not go over what I consider to be advanced optimization tricks such as the use of shared memory , vectorized operations orlaunch bound tuning [link]. By advanced , I do not mean that these topics are especially difficult or out of reach, but only that they require a significant design effort to be used effectively in a production context such as a CFD code like TRUST. In contrast, I believe that the tricks I will give to you in this blogpost are easy enough so that you can and should apply them straightforwardly while porting your code to the GPU in a time limited environement. Moreover, I will not go into GPU model-specific optimizations [link elfarou], the advices are basic enough so that they should beneif on all cards. Disclaimer & Requirements \u00b6 Disclaimers \u00b6 If you think I wrote something that is wrong, please let me know ! I am running my performance tests on Nvidia GPUs, just because they are more easily available to me, and that I am more familiar with the performance tools such as nsight systems (nsys) and nsight compute (ncu). However, note that AMD provides similar profilers, and that the advices that I give here are simple enought so that they apply for GPUs from both vendors. Moreover, I will use Kokkos as the programming model, just because I work with it, and that performance portability is cool . Again, the concepts are simple enought so that you can translate it to your favorite programming model, OpenMP, SYCL, Cuda, Hip. Requirements \u00b6 In this small tutorial, I will assume that you are already familiar with: - Basic C++. - The reason why you might want to use the GPU, and that you need a big enough problem to make full use of it. - What is Kokkos, why you want to use it and how to use it. Some ressources: - Talk by Christian Trott, Co-leader of the Kokkos core team . - Kokkos lecture series (kind of outdated, but you can find a lot of ressources online, alos, join the slack !). - Note: you really should consider using Kokkos, or any other portable programming model. It's good enough so that CEA adopted it for it's legacy codes ! (see the CExA project ). - Basic GPU architecture, in particular: - That you should avoid host to device memory transfers. - The roofline performance model. - What does compute bound / memory bound mean. - Some knowledge about the memory hierarchy (registers, L1/L2 caches, DRAM) and the increasing cost of memory accesses. - Some ressources: - 1h30 lecture from Athena Elfarou on GPU architecture / CUDA programming - 13 lectures on CUDA programming by Bob Crovella - Application-level optimization: - How to build a sensible optimization roadmap. - How to ensure that it is worth it to optimize the kernel you are looking (Don't assume bottleneck, profile, assess, optimize). - How to use Nvidia Nsight System - Some ressouces: - 8th lecture from the Bob Crovella lecture series which focuses on that topic. Outline \u00b6 Use the basic functionnalities of nsight compute. Lancer depuis un cluster, read en local, commande pour un kernel kokkos. Minimuse redundant global memory accesses. Comm vs comp photo demmel James demmel stuff accumulateur tableaux statiques in ncu Ensure memory access are coalesced. Sectors/cache line Layout (Kokkos Layout consipracy) in ncu Minimize redundant math operation, use cheap arithmetics. FMA / vs * in ncu Avoid the use of Local memory by removing: Register spilling accidental stack usage Acc\u00e9s statiques aux tableaux statiques. Cad avoir des bornes de boucles connues au compile time quand on acc\u00e8de \u00e0 des tableaux statique dedans. Ca implique aussi des switch moches parfois quand on a le pattern y=face[x] avec x pas connu au compile time mais tr\u00e8s tr\u00e8s important pour la perf. in ncu, avec les options de compil Understanding occupancy, and when to worry about it: latency hiding The occupancy trap, ILP Pas de MDRange: moins de pression sur les registres Avoid thread divergence: Templater les param\u00e8tres qui change bcp l'execution. bien aussi pour l'occupancy !! Final advices \u00b6 Participate to hackathons !","title":"First Post"},{"location":"posts/post1/#basic-performance-tricks-for-porting-kernels-to-the-gpu","text":"","title":"Basic performance tricks for porting kernels to the GPU."},{"location":"posts/post1/#some-context-and-motivations","text":"Hello world! This is my first blog post. I'm R\u00e9mi Bourgeois, PhD. I am a researcher engineer working at the French Atomic Energy Comission (CEA). I work on the TRUST platform , a HPC (multi-GPU) CFD code that serves as a basis for many research/industrial applications. I was hired by CEA to join the porting effort of this legacy code to the GPU using Kokkos . This is quite a challenging task as the code is 20 years old, and more than 1400 kernels were identified to be ported to the GPU ! As I went and optimized some kernels, something struck me: The nature of the task of porting code to the GPU, especially when time is limited, often lead to small mistakes that can undermine performance. The goal of this blogpost is to give you basic , easy tips to keep in mind when writing / porting / first optimizing your kernels, so that you get a reasonable performance. By applying them, I was able to get: - A 40-50% speedup on a CFD convection kernel from TRUST (obtained on RTX A5000, RTX A6000 Ada and H100 GPUs). Brace yourself : this is a monstruous kernel. - A 40-50% speedup on a CFD diffusion kernel from TRUST (obtained on RTX A6000 Ada and H100 GPUs). - A 20% speedup on a MUSCL reconstruction kernel from the radiative hydrodynamics code heraclescpp - TODO: add ncu reports - A By reasonable I do not mean that you are getting optimal perfomance. In fact, I will not go over what I consider to be advanced optimization tricks such as the use of shared memory , vectorized operations orlaunch bound tuning [link]. By advanced , I do not mean that these topics are especially difficult or out of reach, but only that they require a significant design effort to be used effectively in a production context such as a CFD code like TRUST. In contrast, I believe that the tricks I will give to you in this blogpost are easy enough so that you can and should apply them straightforwardly while porting your code to the GPU in a time limited environement. Moreover, I will not go into GPU model-specific optimizations [link elfarou], the advices are basic enough so that they should beneif on all cards.","title":"Some context and motivations"},{"location":"posts/post1/#disclaimer-requirements","text":"","title":"Disclaimer &amp; Requirements"},{"location":"posts/post1/#disclaimers","text":"If you think I wrote something that is wrong, please let me know ! I am running my performance tests on Nvidia GPUs, just because they are more easily available to me, and that I am more familiar with the performance tools such as nsight systems (nsys) and nsight compute (ncu). However, note that AMD provides similar profilers, and that the advices that I give here are simple enought so that they apply for GPUs from both vendors. Moreover, I will use Kokkos as the programming model, just because I work with it, and that performance portability is cool . Again, the concepts are simple enought so that you can translate it to your favorite programming model, OpenMP, SYCL, Cuda, Hip.","title":"Disclaimers"},{"location":"posts/post1/#requirements","text":"In this small tutorial, I will assume that you are already familiar with: - Basic C++. - The reason why you might want to use the GPU, and that you need a big enough problem to make full use of it. - What is Kokkos, why you want to use it and how to use it. Some ressources: - Talk by Christian Trott, Co-leader of the Kokkos core team . - Kokkos lecture series (kind of outdated, but you can find a lot of ressources online, alos, join the slack !). - Note: you really should consider using Kokkos, or any other portable programming model. It's good enough so that CEA adopted it for it's legacy codes ! (see the CExA project ). - Basic GPU architecture, in particular: - That you should avoid host to device memory transfers. - The roofline performance model. - What does compute bound / memory bound mean. - Some knowledge about the memory hierarchy (registers, L1/L2 caches, DRAM) and the increasing cost of memory accesses. - Some ressources: - 1h30 lecture from Athena Elfarou on GPU architecture / CUDA programming - 13 lectures on CUDA programming by Bob Crovella - Application-level optimization: - How to build a sensible optimization roadmap. - How to ensure that it is worth it to optimize the kernel you are looking (Don't assume bottleneck, profile, assess, optimize). - How to use Nvidia Nsight System - Some ressouces: - 8th lecture from the Bob Crovella lecture series which focuses on that topic.","title":"Requirements"},{"location":"posts/post1/#outline","text":"Use the basic functionnalities of nsight compute. Lancer depuis un cluster, read en local, commande pour un kernel kokkos. Minimuse redundant global memory accesses. Comm vs comp photo demmel James demmel stuff accumulateur tableaux statiques in ncu Ensure memory access are coalesced. Sectors/cache line Layout (Kokkos Layout consipracy) in ncu Minimize redundant math operation, use cheap arithmetics. FMA / vs * in ncu Avoid the use of Local memory by removing: Register spilling accidental stack usage Acc\u00e9s statiques aux tableaux statiques. Cad avoir des bornes de boucles connues au compile time quand on acc\u00e8de \u00e0 des tableaux statique dedans. Ca implique aussi des switch moches parfois quand on a le pattern y=face[x] avec x pas connu au compile time mais tr\u00e8s tr\u00e8s important pour la perf. in ncu, avec les options de compil Understanding occupancy, and when to worry about it: latency hiding The occupancy trap, ILP Pas de MDRange: moins de pression sur les registres Avoid thread divergence: Templater les param\u00e8tres qui change bcp l'execution. bien aussi pour l'occupancy !!","title":"Outline"},{"location":"posts/post1/#final-advices","text":"Participate to hackathons !","title":"Final advices"},{"location":"posts/post2/","text":"","title":"Second Post"}]}